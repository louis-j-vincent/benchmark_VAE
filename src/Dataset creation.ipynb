{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "95b989a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1000/1000 [00:02<00:00, 338.32it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "N = 256\n",
    "X = np.zeros((256,256))\n",
    "\n",
    "def draw_square(X,s,t,ci,cj):\n",
    "    \n",
    "    N = len(X)\n",
    "    l = int(30/(1+np.exp(-20*(t-0.5)))) + 2 #norm \n",
    "    #print(l)\n",
    "    sint = int(np.ceil(s))\n",
    "    for i in range(max(ci-sint,0),min(ci+sint,N)):\n",
    "        if l<8:\n",
    "            S = int((sint**l - (i - ci)**l)**(1/l))\n",
    "        else:\n",
    "            S = sint\n",
    "        X[i,cj-S:cj+S] = 1\n",
    "    return X\n",
    "\n",
    "def define_centers(N,s):\n",
    "    \n",
    "    bin_min, bin_max = max(s,0), min(N-s,N)\n",
    "    ci,cj = np.random.uniform(bin_min,bin_max,size=2)\n",
    "    return int(ci), int(cj)\n",
    "\n",
    "def gen_data(X):\n",
    "    \n",
    "    N = X.shape[0]\n",
    "    s = np.random.uniform(N/10,N/3)\n",
    "    t = np.random.uniform(0,1)\n",
    "    ci,cj = define_centers(N,s)\n",
    "    X = draw_square(X,s,t,ci,cj)\n",
    "    return X\n",
    "\n",
    "\n",
    "def gen_timeseries(T,M,N):\n",
    "    X = np.zeros((M,T,N,N))\n",
    "    t1 = np.random.uniform(size=M) #ending temperatures\n",
    "    Temperatures = np.array([np.linspace(0,t1[i],T) for i in range(M)]).T\n",
    "    \n",
    "    s0,s1 = np.random.uniform(N/10,N/3,size=M), np.random.uniform(N/10,N/3,size=M) #ending sizes\n",
    "    Sizes = np.array([np.linspace(s0[i],s1[i],T) for i in range(M)]).T#.astype(int)\n",
    "    \n",
    "    c0, c1 = np.array([define_centers(N,Sizes[0,i]) for i in range(M)]), np.array([define_centers(N,Sizes[-1,i]) for i in range(M)])\n",
    "    Centersx, Centersy = np.array([np.linspace(c0[i,0],c1[i,0],T) for i in range(M)]).astype(int), np.array([np.linspace(c0[i,1],c1[i,1],T) for i in range(M)]).astype(int)\n",
    "    \n",
    "    for i in tqdm(range(M)):\n",
    "        for t in range(T):\n",
    "            X[i,t] = draw_square(X[i,t],Sizes[t,i],Temperatures[t,i],Centersx[i,t],Centersy[i,t])\n",
    "            \n",
    "    return X, Centersx, Centersy, Sizes, Temperatures\n",
    "    \n",
    "T, M, N = 100, 1000, 28\n",
    "X, Cx, Cy, S, T = gen_timeseries(T,M,N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e49f1cdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb3b6cce9a0>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X[3,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "160db321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "device = torch.device('mps')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f133ed9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythae.models import t_AE, t_AEConfig\n",
    "from pythae.trainers import BaseTrainerConfig\n",
    "from pythae.pipelines.training import TrainingPipeline\n",
    "from pythae.models.nn.benchmarks.mnist import Encoder_AE_MNIST, Decoder_AE_MNIST\n",
    "#from pythae.models.nn import Encoder_vAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8755be0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = t_AEConfig(\n",
    "    input_dim=(1, N, N),\n",
    "    latent_dim=3\n",
    ")\n",
    "\n",
    "model = t_AE(\n",
    "    model_config=model_config,\n",
    "    encoder=Encoder_AE_MNIST(model_config), \n",
    "    decoder=Decoder_AE_MNIST(model_config) \n",
    ")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f0b67572",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, eval_dataset = X[:-M//10], X[-M//10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c53feedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing train data...\n",
      "Preprocessing eval data...\n",
      "\n",
      "Using Base Trainer\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processor processed data\n",
      "Processor ade to dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model passed sanity check !\n",
      "\n",
      "Created my_model/AE_training_2022-12-15_22-06-13. \n",
      "Training config, checkpoints and final model will be saved here.\n",
      "\n",
      "Successfully launched training !\n",
      "\n",
      "\n",
      "\n",
      "Training of epoch 1/10:   0%|                        | 0/900 [00:00<?, ?batch/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Eval of epoch 1/10:   0%|                            | 0/100 [00:00<?, ?batch/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Training of epoch 1/10:   0%|                | 1/900 [00:02<34:23,  2.30s/batch]\u001b[A\u001b[A\n",
      "\n",
      "Training of epoch 1/10:   0%|                | 2/900 [00:04<30:51,  2.06s/batch]\u001b[A\u001b[A\n",
      "\n",
      "Training of epoch 1/10:   0%|                | 3/900 [00:06<32:13,  2.16s/batch]\u001b[A\u001b[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [84], line 13\u001b[0m\n\u001b[1;32m      1\u001b[0m config \u001b[38;5;241m=\u001b[39m BaseTrainerConfig(\n\u001b[1;32m      2\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmy_model\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      3\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m,\n\u001b[1;32m      4\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m      5\u001b[0m     num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, \u001b[38;5;66;03m# Change this to train the model a bit more\u001b[39;00m\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      8\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m TrainingPipeline(\n\u001b[1;32m      9\u001b[0m     training_config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[1;32m     10\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel\n\u001b[1;32m     11\u001b[0m )\n\u001b[0;32m---> 13\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_dataset\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/benchmark_VAE/src/pythae/pipelines/training.py:178\u001b[0m, in \u001b[0;36mTrainingPipeline.__call__\u001b[0;34m(self, train_data, eval_data, train_data_alpha, eval_data_alpha, log_output_dir)\u001b[0m\n\u001b[1;32m    169\u001b[0m     trainer \u001b[38;5;241m=\u001b[39m BaseTrainer(\n\u001b[1;32m    170\u001b[0m         model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel,\n\u001b[1;32m    171\u001b[0m         train_dataset\u001b[38;5;241m=\u001b[39mtrain_dataset,\n\u001b[1;32m    172\u001b[0m         eval_dataset\u001b[38;5;241m=\u001b[39meval_dataset,\n\u001b[1;32m    173\u001b[0m         training_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_config\n\u001b[1;32m    174\u001b[0m     )\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m trainer\n\u001b[0;32m--> 178\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_output_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_output_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/benchmark_VAE/src/pythae/trainers/base_trainer/base_trainer.py:315\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[0;34m(self, log_output_dir)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_epoch_begin(\n\u001b[1;32m    307\u001b[0m     training_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_config,\n\u001b[1;32m    308\u001b[0m     epoch\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m    309\u001b[0m     train_loader\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loader,\n\u001b[1;32m    310\u001b[0m     eval_loader\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval_loader,\n\u001b[1;32m    311\u001b[0m )\n\u001b[1;32m    313\u001b[0m metrics \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 315\u001b[0m epoch_train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    316\u001b[0m metrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_epoch_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m epoch_train_loss\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/benchmark_VAE/src/pythae/trainers/base_trainer/base_trainer.py:464\u001b[0m, in \u001b[0;36mBaseTrainer.train_step\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m    458\u001b[0m model_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\n\u001b[1;32m    459\u001b[0m     inputs, epoch\u001b[38;5;241m=\u001b[39mepoch, dataset_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loader\u001b[38;5;241m.\u001b[39mdataset)\n\u001b[1;32m    460\u001b[0m )\n\u001b[1;32m    462\u001b[0m loss \u001b[38;5;241m=\u001b[39m model_output\u001b[38;5;241m.\u001b[39mloss\n\u001b[0;32m--> 464\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    467\u001b[0m epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "config = BaseTrainerConfig(\n",
    "    output_dir='my_model',\n",
    "    learning_rate=1e-4,\n",
    "    batch_size=1,\n",
    "    num_epochs=10, # Change this to train the model a bit more\n",
    ")\n",
    "\n",
    "pipeline = TrainingPipeline(\n",
    "    training_config=config,\n",
    "    model=model\n",
    ")\n",
    "\n",
    "pipeline(\n",
    "    train_data=train_dataset,\n",
    "    eval_data=eval_dataset\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
