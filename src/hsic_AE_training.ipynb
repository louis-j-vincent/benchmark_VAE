{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "tV64Au2I804z"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "device = torch.device('mps')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "5yvBWoo4804z"
   },
   "outputs": [],
   "source": [
    "mnist_trainset = datasets.MNIST(root='../../data', train=True, download=True, transform=None)\n",
    "\n",
    "train_dataset = mnist_trainset.data[:-10000].reshape(-1, 1, 28, 28) / 255.\n",
    "eval_dataset = mnist_trainset.data[-10000:].reshape(-1, 1, 28, 28) / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Df5uuFCF-O1-"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "##corrupt data\n",
    "def corrupt_data(data):\n",
    "    data[data>0.9] = 1\n",
    "    data[data<0.9] = 0\n",
    "    square_size = data.shape[-1]\n",
    "    center_coord = np.random.randint(0,square_size,(2,data.shape[0]))\n",
    "    square_size = np.repeat(np.random.randint(0,square_size//2,data.shape[0]).reshape(1,-1),2,axis=0)\n",
    "    upper_left_coord = np.minimum(np.maximum(center_coord - (square_size//2),0),square_size)\n",
    "    for i in range(data.shape[0]):\n",
    "        data[i,:,upper_left_coord[0,i]:upper_left_coord[0,i]+square_size[0,i],upper_left_coord[1,i]:upper_left_coord[1,i]+square_size[1,i]] = -10\n",
    "    return data\n",
    "\n",
    "train_dataset = corrupt_data(train_dataset)\n",
    "eval_dataset = corrupt_data(eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "NDKeAkzc804z"
   },
   "outputs": [],
   "source": [
    "from pythae.models import IC_AE, IC_AEConfig\n",
    "from pythae.trainers import BaseTrainerConfig\n",
    "from pythae.pipelines.training import TrainingPipeline\n",
    "from pythae.models.nn.benchmarks.mnist import Encoder_vAE_MNIST, Decoder_AE_MNIST\n",
    "#from pythae.models.nn import Encoder_vAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "r_AiEKrO8040"
   },
   "outputs": [],
   "source": [
    "config = BaseTrainerConfig(\n",
    "    output_dir='my_model',\n",
    "    learning_rate=1e-4,\n",
    "    batch_size=500,\n",
    "    num_epochs=10, # Change this to train the model a bit more\n",
    ")\n",
    "\n",
    "\n",
    "model_config = IC_AEConfig(\n",
    "    input_dim=(1, 28, 28),\n",
    "    latent_dim=32\n",
    ")\n",
    "\n",
    "model = IC_AE(\n",
    "    model_config=model_config\n",
    ")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.nU = 5\n",
    "model.beta = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "choo34Ue8040"
   },
   "outputs": [],
   "source": [
    "pipeline = TrainingPipeline(\n",
    "    training_config=config,\n",
    "    model=model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7PYuekm38040",
    "outputId": "de44f895-b35e-42a8-f69d-775ab4180fc9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing train data...\n",
      "Preprocessing eval data...\n",
      "\n",
      "Using Base Trainer\n",
      "\n",
      "Model passed sanity check !\n",
      "\n",
      "Created my_model/AE_training_2022-12-13_21-54-20. \n",
      "Training config, checkpoints and final model will be saved here.\n",
      "\n",
      "Successfully launched training !\n",
      "\n",
      "Training of epoch 1/10:   0%|                        | 0/100 [00:00<?, ?batch/s]\n",
      "Training of epoch 1/10: 100%|██████████████| 100/100 [00:07<00:00, 13.14batch/s]\u001b[A\n",
      "Eval of epoch 1/10:   5%|█                    | 1/20 [00:07<02:23,  7.54s/batch]\u001b[A\n",
      "Eval of epoch 1/10:  25%|█████▎               | 5/20 [00:07<00:17,  1.15s/batch]\u001b[A\n",
      "Eval of epoch 1/10:  45%|█████████▍           | 9/20 [00:07<00:05,  1.88batch/s]\u001b[A\n",
      "Eval of epoch 1/10:  65%|█████████████       | 13/20 [00:07<00:02,  3.23batch/s]\u001b[A\n",
      "Training of epoch 1/10: 100%|██████████████| 100/100 [00:08<00:00, 12.44batch/s]\u001b[A\n",
      "Eval of epoch 1/10: 100%|████████████████████| 20/20 [00:08<00:00,  2.49batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 120.31\n",
      "Eval loss: 68.3116\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 2/10:   0%|                        | 0/100 [00:00<?, ?batch/s]\n",
      "Training of epoch 2/10: 100%|██████████████| 100/100 [00:06<00:00, 13.38batch/s]\u001b[A\n",
      "Eval of epoch 2/10:   5%|█                    | 1/20 [00:06<02:11,  6.94s/batch]\u001b[A\n",
      "Eval of epoch 2/10:  25%|█████▎               | 5/20 [00:07<00:15,  1.06s/batch]\u001b[A\n",
      "Eval of epoch 2/10:  45%|█████████▍           | 9/20 [00:07<00:05,  2.03batch/s]\u001b[A\n",
      "Eval of epoch 2/10:  65%|█████████████       | 13/20 [00:07<00:02,  3.45batch/s]\u001b[A\n",
      "Training of epoch 2/10: 100%|██████████████| 100/100 [00:07<00:00, 13.37batch/s]\u001b[A\n",
      "Eval of epoch 2/10: 100%|████████████████████| 20/20 [00:07<00:00,  2.67batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 59.8474\n",
      "Eval loss: 55.393\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 3/10:   0%|                        | 0/100 [00:00<?, ?batch/s]\n",
      "Training of epoch 3/10: 100%|██████████████| 100/100 [00:07<00:00, 14.46batch/s]\u001b[A\n",
      "Eval of epoch 3/10:   5%|█                    | 1/20 [00:07<02:14,  7.07s/batch]\u001b[A\n",
      "Eval of epoch 3/10:  25%|█████▎               | 5/20 [00:07<00:16,  1.08s/batch]\u001b[A\n",
      "Eval of epoch 3/10:  45%|█████████▍           | 9/20 [00:07<00:05,  1.99batch/s]\u001b[A\n",
      "Eval of epoch 3/10:  65%|█████████████       | 13/20 [00:07<00:02,  3.40batch/s]\u001b[A\n",
      "Training of epoch 3/10: 100%|██████████████| 100/100 [00:07<00:00, 13.12batch/s]\u001b[A\n",
      "Eval of epoch 3/10: 100%|████████████████████| 20/20 [00:07<00:00,  2.62batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 53.1381\n",
      "Eval loss: 50.9173\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 4/10:   0%|                        | 0/100 [00:00<?, ?batch/s]\n",
      "Training of epoch 4/10: 100%|██████████████| 100/100 [00:07<00:00, 13.59batch/s]\u001b[A\n",
      "Eval of epoch 4/10:   5%|█                    | 1/20 [00:07<02:23,  7.57s/batch]\u001b[A\n",
      "Eval of epoch 4/10:  30%|██████▎              | 6/20 [00:07<00:13,  1.05batch/s]\u001b[A\n",
      "Eval of epoch 4/10:  50%|██████████          | 10/20 [00:07<00:04,  2.05batch/s]\u001b[A\n",
      "Eval of epoch 4/10:  75%|███████████████     | 15/20 [00:07<00:01,  3.69batch/s]\u001b[A\n",
      "Training of epoch 4/10: 100%|██████████████| 100/100 [00:08<00:00, 12.41batch/s]\u001b[A\n",
      "Eval of epoch 4/10: 100%|████████████████████| 20/20 [00:08<00:00,  2.48batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 49.9622\n",
      "Eval loss: 48.9677\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 5/10:   0%|                        | 0/100 [00:00<?, ?batch/s]\n",
      "Training of epoch 5/10: 100%|██████████████| 100/100 [00:06<00:00, 15.46batch/s]\u001b[A\n",
      "Eval of epoch 5/10:   5%|█                    | 1/20 [00:06<02:06,  6.65s/batch]\u001b[A\n",
      "Eval of epoch 5/10:  30%|██████▎              | 6/20 [00:06<00:11,  1.19batch/s]\u001b[A\n",
      "Eval of epoch 5/10:  55%|███████████         | 11/20 [00:06<00:03,  2.60batch/s]\u001b[A\n",
      "Eval of epoch 5/10:  75%|███████████████     | 15/20 [00:06<00:01,  4.09batch/s]\u001b[A\n",
      "Training of epoch 5/10: 100%|██████████████| 100/100 [00:07<00:00, 14.05batch/s]\u001b[A\n",
      "Eval of epoch 5/10: 100%|████████████████████| 20/20 [00:07<00:00,  2.81batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 48.7092\n",
      "Eval loss: 48.2655\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 6/10:   0%|                        | 0/100 [00:00<?, ?batch/s]\n",
      "Training of epoch 6/10: 100%|██████████████| 100/100 [00:06<00:00, 15.66batch/s]\u001b[A\n",
      "Eval of epoch 6/10:   5%|█                    | 1/20 [00:06<02:02,  6.45s/batch]\u001b[A\n",
      "Eval of epoch 6/10:  30%|██████▎              | 6/20 [00:06<00:11,  1.23batch/s]\u001b[A\n",
      "Eval of epoch 6/10:  55%|███████████         | 11/20 [00:06<00:03,  2.67batch/s]\u001b[A\n",
      "Eval of epoch 6/10:  75%|███████████████     | 15/20 [00:06<00:01,  4.19batch/s]\u001b[A\n",
      "Training of epoch 6/10: 100%|██████████████| 100/100 [00:06<00:00, 14.44batch/s]\u001b[A\n",
      "Eval of epoch 6/10: 100%|████████████████████| 20/20 [00:06<00:00,  2.89batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 48.1513\n",
      "Eval loss: 47.8789\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 7/10:   0%|                        | 0/100 [00:00<?, ?batch/s]\n",
      "Training of epoch 7/10: 100%|██████████████| 100/100 [00:07<00:00, 13.06batch/s]\u001b[A\n",
      "Eval of epoch 7/10:   5%|█                    | 1/20 [00:07<02:13,  7.05s/batch]\u001b[A\n",
      "Eval of epoch 7/10:  10%|██                   | 2/20 [00:07<00:53,  2.96s/batch]\u001b[A\n",
      "Eval of epoch 7/10:  35%|███████▎             | 7/20 [00:07<00:07,  1.70batch/s]\u001b[A\n",
      "Eval of epoch 7/10:  60%|████████████        | 12/20 [00:07<00:02,  3.50batch/s]\u001b[A\n",
      "Eval of epoch 7/10:  80%|████████████████    | 16/20 [00:07<00:00,  5.35batch/s]\u001b[A\n",
      "Training of epoch 7/10: 100%|██████████████| 100/100 [00:07<00:00, 13.17batch/s]\u001b[A\n",
      "Eval of epoch 7/10: 100%|████████████████████| 20/20 [00:07<00:00,  2.64batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 47.7473\n",
      "Eval loss: 47.5454\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 8/10:   0%|                        | 0/100 [00:00<?, ?batch/s]\n",
      "Training of epoch 8/10: 100%|██████████████| 100/100 [00:06<00:00, 16.18batch/s]\u001b[A\n",
      "Eval of epoch 8/10:   5%|█                    | 1/20 [00:06<02:04,  6.56s/batch]\u001b[A\n",
      "Eval of epoch 8/10:  25%|█████▎               | 5/20 [00:06<00:15,  1.00s/batch]\u001b[A\n",
      "Eval of epoch 8/10:  40%|████████▍            | 8/20 [00:06<00:06,  1.85batch/s]\u001b[A\n",
      "Eval of epoch 8/10:  60%|████████████        | 12/20 [00:06<00:02,  3.38batch/s]\u001b[A\n",
      "Training of epoch 8/10: 100%|██████████████| 100/100 [00:07<00:00, 14.11batch/s]\u001b[A\n",
      "Eval of epoch 8/10: 100%|████████████████████| 20/20 [00:07<00:00,  2.82batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 47.3897\n",
      "Eval loss: 47.2614\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 9/10:   0%|                        | 0/100 [00:00<?, ?batch/s]\n",
      "Training of epoch 9/10: 100%|██████████████| 100/100 [00:06<00:00, 16.24batch/s]\u001b[A\n",
      "Eval of epoch 9/10:   5%|█                    | 1/20 [00:06<02:01,  6.38s/batch]\u001b[A\n",
      "Eval of epoch 9/10:  30%|██████▎              | 6/20 [00:06<00:11,  1.24batch/s]\u001b[A\n",
      "Eval of epoch 9/10:  55%|███████████         | 11/20 [00:06<00:03,  2.70batch/s]\u001b[A\n",
      "Eval of epoch 9/10:  75%|███████████████     | 15/20 [00:06<00:01,  4.23batch/s]\u001b[A\n",
      "Training of epoch 9/10: 100%|██████████████| 100/100 [00:06<00:00, 14.61batch/s]\u001b[A\n",
      "Eval of epoch 9/10: 100%|████████████████████| 20/20 [00:06<00:00,  2.92batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 47.0297\n",
      "Eval loss: 47.1018\n",
      "--------------------------------------------------------------------------\n",
      "Training of epoch 10/10:   0%|                       | 0/100 [00:00<?, ?batch/s]\n",
      "Training of epoch 10/10: 100%|█████████████| 100/100 [00:06<00:00, 15.49batch/s]\u001b[A\n",
      "Eval of epoch 10/10:   5%|█                   | 1/20 [00:06<02:06,  6.66s/batch]\u001b[A\n",
      "Eval of epoch 10/10:  30%|██████              | 6/20 [00:06<00:11,  1.19batch/s]\u001b[A\n",
      "Eval of epoch 10/10:  55%|██████████▍        | 11/20 [00:06<00:03,  2.59batch/s]\u001b[A\n",
      "Eval of epoch 10/10:  75%|██████████████▎    | 15/20 [00:07<00:01,  4.05batch/s]\u001b[A\n",
      "Training of epoch 10/10: 100%|█████████████| 100/100 [00:07<00:00, 14.01batch/s]\u001b[A\n",
      "Eval of epoch 10/10: 100%|███████████████████| 20/20 [00:07<00:00,  2.80batch/s]\n",
      "--------------------------------------------------------------------------\n",
      "Train loss: 46.601\n",
      "Eval loss: 46.7451\n",
      "--------------------------------------------------------------------------\n",
      "Training ended!\n",
      "Saved final model in my_model/AE_training_2022-12-13_21-54-20/final_model\n"
     ]
    }
   ],
   "source": [
    "pipeline(\n",
    "    train_data=train_dataset,\n",
    "    eval_data=eval_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706,\n",
       "          0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.1176, 0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922,\n",
       "          0.9922, 0.9922, 0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n",
       "          0.9333, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
       "          0.9922, 0.9843, 0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706,\n",
       "          0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137,\n",
       "          0.9686, 0.9451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.3137, 0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000,\n",
       "          0.1686, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275,\n",
       "          0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922,\n",
       "          0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294,\n",
       "          0.9922, 0.9922, 0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
       "          0.3647, 0.9882, 0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.9765, 0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098,\n",
       "          0.7176, 0.9922, 0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922,\n",
       "          0.9922, 0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922,\n",
       "          0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0902, 0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765,\n",
       "          0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706,\n",
       "          0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922,\n",
       "          0.9922, 0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922,\n",
       "          0.8314, 0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_dataset[:10]\n",
    "z = model.encoder(x).embedding\n",
    "x_rec = model.decoder(z).reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: - \n",
      "\n",
      "Updating matplotlib is constricted by \n",
      "\n",
      "anaconda -> requires matplotlib==3.5.1=py39hecd8cb5_1\n",
      "\n",
      "If you are sure you want an update of your package either try `conda update --all` or install a specific version of the package you want using `conda install <pkg>=<version>`\n",
      "\n",
      "done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/louis/opt/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - matplotlib\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    conda-22.11.1              |   py39hecd8cb5_3         941 KB\n",
      "    conda-package-handling-1.9.0|   py39hca72f7f_1         1.5 MB\n",
      "    pyjwt-2.4.0                |   py39hecd8cb5_0          35 KB\n",
      "    ruamel.yaml-0.17.21        |   py39hca72f7f_0         179 KB\n",
      "    ruamel.yaml.clib-0.2.6     |   py39hca72f7f_1         126 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         2.8 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  ruamel.yaml        pkgs/main/osx-64::ruamel.yaml-0.17.21-py39hca72f7f_0 None\n",
      "  ruamel.yaml.clib   pkgs/main/osx-64::ruamel.yaml.clib-0.2.6-py39hca72f7f_1 None\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  conda                               22.9.0-py39hecd8cb5_0 --> 22.11.1-py39hecd8cb5_3 None\n",
      "  conda-package-han~                   1.8.1-py39hca72f7f_0 --> 1.9.0-py39hca72f7f_1 None\n",
      "  pyjwt                                2.1.0-py39hecd8cb5_0 --> 2.4.0-py39hecd8cb5_0 None\n",
      "\n",
      "\n",
      "Proceed ([y]/n)? ^C\n",
      "\n",
      "CondaSystemExit: \n",
      "Operation aborted.  Exiting.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda update matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fbad02b7bb0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_rec[3].detach()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0246,  0.0197, -0.0422,  ...,  0.0372,  0.0016, -0.0013],\n",
      "        [ 0.0246,  0.0197, -0.0422,  ...,  0.0372,  0.0016, -0.0013],\n",
      "        [ 0.0277,  0.0211, -0.0342,  ...,  0.0384,  0.0036,  0.0015],\n",
      "        ...,\n",
      "        [ 0.0246,  0.0197, -0.0422,  ...,  0.0372,  0.0016, -0.0013],\n",
      "        [ 0.0216,  0.0195, -0.0413,  ...,  0.0346,  0.0059, -0.0026],\n",
      "        [ 0.0244,  0.0198, -0.0424,  ...,  0.0371,  0.0013, -0.0014]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DpyISPS48041"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pythae.models import AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ykdg1I_t8041"
   },
   "outputs": [],
   "source": [
    "last_training = sorted(os.listdir('my_model'))[-1]\n",
    "trained_model = AutoModel.load_from_folder(os.path.join('my_model', last_training, 'final_model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YKlSphBI8041"
   },
   "outputs": [],
   "source": [
    "from pythae.samplers import NormalSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W7ZQiPLA8042"
   },
   "outputs": [],
   "source": [
    "# create normal sampler\n",
    "normal_samper = NormalSampler(\n",
    "    model=trained_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8tH_T3XY8042"
   },
   "outputs": [],
   "source": [
    "# sample\n",
    "gen_data = normal_samper.sample(\n",
    "    num_samples=25\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iqrYkb1N8042"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2NqfFbeN8042"
   },
   "outputs": [],
   "source": [
    "# show results with normal sampler\n",
    "fig, axes = plt.subplots(nrows=5, ncols=5, figsize=(10, 10))\n",
    "\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        axes[i][j].imshow(gen_data[i*5 +j].cpu().squeeze(0), cmap='gray')\n",
    "        axes[i][j].axis('off')\n",
    "plt.tight_layout(pad=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BGn-niYX8042"
   },
   "outputs": [],
   "source": [
    "from pythae.samplers import GaussianMixtureSampler, GaussianMixtureSamplerConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4K9kcH0y8042"
   },
   "outputs": [],
   "source": [
    "# set up GMM sampler config\n",
    "gmm_sampler_config = GaussianMixtureSamplerConfig(\n",
    "    n_components=10\n",
    ")\n",
    "\n",
    "# create gmm sampler\n",
    "gmm_sampler = GaussianMixtureSampler(\n",
    "    sampler_config=gmm_sampler_config,\n",
    "    model=trained_model\n",
    ")\n",
    "\n",
    "# fit the sampler\n",
    "gmm_sampler.fit(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lloDLiOe8043"
   },
   "outputs": [],
   "source": [
    "# sample\n",
    "gen_data = gmm_sampler.sample(\n",
    "    num_samples=25\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k3fXB2zb8043"
   },
   "outputs": [],
   "source": [
    "# show results with gmm sampler\n",
    "fig, axes = plt.subplots(nrows=5, ncols=5, figsize=(10, 10))\n",
    "\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        axes[i][j].imshow(gen_data[i*5 +j].cpu().squeeze(0), cmap='gray')\n",
    "        axes[i][j].axis('off')\n",
    "plt.tight_layout(pad=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nj0tOb7t8043"
   },
   "source": [
    "## ... the other samplers work the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JqfHhaE38043"
   },
   "source": [
    "## Visualizing reconstructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JOm-5zbi8043"
   },
   "outputs": [],
   "source": [
    "reconstructions = trained_model.reconstruct(eval_dataset[:25].to(device)).detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PjGtIoSH8044"
   },
   "outputs": [],
   "source": [
    "# show reconstructions\n",
    "fig, axes = plt.subplots(nrows=5, ncols=5, figsize=(10, 10))\n",
    "\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        axes[i][j].imshow(reconstructions[i*5 + j].cpu().squeeze(0), cmap='gray')\n",
    "        axes[i][j].axis('off')\n",
    "plt.tight_layout(pad=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dv1hGuac8044"
   },
   "outputs": [],
   "source": [
    "# show the true data\n",
    "fig, axes = plt.subplots(nrows=5, ncols=5, figsize=(10, 10))\n",
    "\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        axes[i][j].imshow(eval_dataset[i*5 +j].cpu().squeeze(0), cmap='gray')\n",
    "        axes[i][j].axis('off')\n",
    "plt.tight_layout(pad=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1gC9SpKU8044"
   },
   "source": [
    "## Visualizing interpolations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IZjhayQv8044"
   },
   "outputs": [],
   "source": [
    "interpolations = trained_model.interpolate(eval_dataset[:5].to(device), eval_dataset[5:10].to(device), granularity=10).detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a7MWlY1w8045"
   },
   "outputs": [],
   "source": [
    "# show interpolations\n",
    "fig, axes = plt.subplots(nrows=5, ncols=10, figsize=(10, 5))\n",
    "\n",
    "for i in range(5):\n",
    "    for j in range(10):\n",
    "        axes[i][j].imshow(interpolations[i, j].cpu().squeeze(0), cmap='gray')\n",
    "        axes[i][j].axis('off')\n",
    "plt.tight_layout(pad=0.)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "interpreter": {
   "hash": "3efa06c4da850a09a4898b773c7e91b0da3286dbbffa369a8099a14a8fa43098"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
